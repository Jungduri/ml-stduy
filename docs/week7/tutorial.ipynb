{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian network tutorial powered by pgmpy\n",
    "conda install -c ankurankan pgmpy\n",
    "pip install jupyter\n",
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Library\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "alarm_model = BayesianNetwork(\n",
    "    [\n",
    "        (\"Burglary\", \"Alarm\"),\n",
    "        (\"Earthquake\", \"Alarm\"),\n",
    "        (\"Alarm\", \"JohnCalls\"),\n",
    "        (\"Alarm\", \"MaryCalls\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters using CPT\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "cpd_burglary = TabularCPD(\n",
    "    variable=\"Burglary\", variable_card=2, values=[[0.999], [0.001]]\n",
    ")\n",
    "cpd_earthquake = TabularCPD(\n",
    "    variable=\"Earthquake\", variable_card=2, values=[[0.998], [0.002]]\n",
    ")\n",
    "cpd_alarm = TabularCPD(\n",
    "    variable=\"Alarm\",\n",
    "    variable_card=2,\n",
    "    values=[[0.999, 0.71, 0.06, 0.05], [0.001, 0.29, 0.94, 0.95]],\n",
    "    evidence=[\"Burglary\", \"Earthquake\"],\n",
    "    evidence_card=[2, 2],\n",
    ")\n",
    "cpd_johncalls = TabularCPD(\n",
    "    variable=\"JohnCalls\",\n",
    "    variable_card=2,\n",
    "    values=[[0.95, 0.1], [0.05, 0.9]],\n",
    "    evidence=[\"Alarm\"],\n",
    "    evidence_card=[2],\n",
    ")\n",
    "cpd_marycalls = TabularCPD(\n",
    "    variable=\"MaryCalls\",\n",
    "    variable_card=2,\n",
    "    values=[[0.1, 0.7], [0.9, 0.3]],\n",
    "    evidence=[\"Alarm\"],\n",
    "    evidence_card=[2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associating the parameters with the model structure\n",
    "alarm_model.add_cpds(\n",
    "    cpd_burglary, cpd_earthquake, cpd_alarm, cpd_johncalls, cpd_marycalls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the cpds are valid for the model\n",
    "alarm_model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing nodes of the model\n",
    "alarm_model.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing edges of the model\n",
    "alarm_model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking independcies of a node\n",
    "alarm_model.local_independencies(\"Burglary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all Independencies\n",
    "alarm_model.get_independencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Learning in Discrete Bayesian Networks\n",
    "\n",
    "In this notebook, we show an example for learning the parameters (CPDs) of a Discrete Bayesian Network given the data and the model structure. pgmpy has two main methods for learning the parameters:\n",
    "\n",
    "* MaximumLikelihood Estimator (pgmpy.estimators.MaximumLikelihoodEstimator)\n",
    "* Bayesian Estimator (pgmpy.estimators.BayesianEstimator)\n",
    "* Expectation Maximization (pgmpy.estimators.ExpectationMaximization)\n",
    "In the examples, we will try to generate some data from given models and then try to learn the model parameters back from the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e200a6f156e74f08942d372fe23bf16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>CVP</th>\n",
       "      <th>PCWP</th>\n",
       "      <th>HYPOVOLEMIA</th>\n",
       "      <th>LVEDVOLUME</th>\n",
       "      <th>LVFAILURE</th>\n",
       "      <th>STROKEVOLUME</th>\n",
       "      <th>ERRLOWOUTPUT</th>\n",
       "      <th>HRBP</th>\n",
       "      <th>HREKG</th>\n",
       "      <th>...</th>\n",
       "      <th>MINVOLSET</th>\n",
       "      <th>VENTMACH</th>\n",
       "      <th>VENTTUBE</th>\n",
       "      <th>VENTLUNG</th>\n",
       "      <th>VENTALV</th>\n",
       "      <th>ARTCO2</th>\n",
       "      <th>CATECHOL</th>\n",
       "      <th>HR</th>\n",
       "      <th>CO</th>\n",
       "      <th>BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  HISTORY     CVP    PCWP HYPOVOLEMIA LVEDVOLUME LVFAILURE STROKEVOLUME  \\\n",
       "0   FALSE  NORMAL  NORMAL       FALSE     NORMAL     FALSE       NORMAL   \n",
       "1   FALSE  NORMAL  NORMAL       FALSE     NORMAL     FALSE       NORMAL   \n",
       "2   FALSE  NORMAL  NORMAL       FALSE     NORMAL     FALSE       NORMAL   \n",
       "3   FALSE    HIGH    HIGH        TRUE       HIGH     FALSE       NORMAL   \n",
       "4   FALSE  NORMAL  NORMAL        TRUE     NORMAL     FALSE       NORMAL   \n",
       "\n",
       "  ERRLOWOUTPUT    HRBP HREKG  ... MINVOLSET VENTMACH VENTTUBE VENTLUNG  \\\n",
       "0        FALSE    HIGH  HIGH  ...    NORMAL   NORMAL     ZERO      LOW   \n",
       "1        FALSE    HIGH  HIGH  ...    NORMAL   NORMAL      LOW      LOW   \n",
       "2        FALSE    HIGH  HIGH  ...    NORMAL     ZERO     ZERO     ZERO   \n",
       "3         TRUE  NORMAL   LOW  ...    NORMAL   NORMAL      LOW     ZERO   \n",
       "4        FALSE    HIGH  HIGH  ...    NORMAL   NORMAL      LOW     ZERO   \n",
       "\n",
       "  VENTALV ARTCO2 CATECHOL      HR      CO      BP  \n",
       "0    HIGH    LOW     HIGH    HIGH    HIGH     LOW  \n",
       "1    HIGH    LOW     HIGH    HIGH    HIGH    HIGH  \n",
       "2    ZERO   HIGH     HIGH    HIGH    HIGH    HIGH  \n",
       "3    ZERO   HIGH   NORMAL  NORMAL  NORMAL  NORMAL  \n",
       "4    ZERO   HIGH     HIGH    HIGH    HIGH     LOW  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Generate some data\n",
    "# Use the alarm model to generate data from it.\n",
    "\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "import numpy as np\n",
    "alarm_model = get_example_model(\"alarm\")\n",
    "samples = BayesianModelSampling(alarm_model).forward_sample(size=int(1e5))\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('HYPOVOLEMIA', 'LVEDVOLUME', 'STROKEVOLUME', 'CVP', 'PCWP', 'LVFAILURE', 'HISTORY', 'CO', 'ERRLOWOUTPUT', 'HRBP', 'ERRCAUTER', 'HREKG', 'HRSAT', 'INSUFFANESTH', 'CATECHOL', 'ANAPHYLAXIS', 'TPR', 'BP', 'KINKEDTUBE', 'PRESS', 'VENTLUNG', 'FIO2', 'PVSAT', 'SAO2', 'PULMEMBOLUS', 'PAP', 'SHUNT', 'INTUBATION', 'MINVOL', 'VENTALV', 'DISCONNECT', 'VENTTUBE', 'MINVOLSET', 'VENTMACH', 'EXPCO2', 'ARTCO2', 'HR'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Define a model structure\n",
    "# Defining the Bayesian Model structure\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "model_struct = BayesianNetwork(ebunch=alarm_model.edges())\n",
    "model_struct.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "| FIO2(LOW)    | 0.05 |\n",
      "+--------------+------+\n",
      "| FIO2(NORMAL) | 0.95 |\n",
      "+--------------+------+\n",
      "+-------------+-----+----------------------+\n",
      "| LVEDVOLUME  | ... | LVEDVOLUME(NORMAL)   |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(HIGH)   | ... | 0.009998862149399783 |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(LOW)    | ... | 0.03971098594754509  |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(NORMAL) | ... | 0.9502901519030551   |\n",
      "+-------------+-----+----------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(HYPOVOLEMIA:2) at 0x7f1c092b0b90>,\n",
       " <TabularCPD representing P(LVEDVOLUME:3 | HYPOVOLEMIA:2, LVFAILURE:2) at 0x7f1c092b54d0>,\n",
       " <TabularCPD representing P(STROKEVOLUME:3 | HYPOVOLEMIA:2, LVFAILURE:2) at 0x7f1c092b5e50>,\n",
       " <TabularCPD representing P(CVP:3 | LVEDVOLUME:3) at 0x7f1c092b0290>,\n",
       " <TabularCPD representing P(PCWP:3 | LVEDVOLUME:3) at 0x7f1c093c9390>,\n",
       " <TabularCPD representing P(LVFAILURE:2) at 0x7f1c0929fd90>,\n",
       " <TabularCPD representing P(HISTORY:2 | LVFAILURE:2) at 0x7f1c0929fb10>,\n",
       " <TabularCPD representing P(CO:3 | HR:3, STROKEVOLUME:3) at 0x7f1c08a57650>,\n",
       " <TabularCPD representing P(ERRLOWOUTPUT:2) at 0x7f1c092a9d90>,\n",
       " <TabularCPD representing P(HRBP:3 | ERRLOWOUTPUT:2, HR:3) at 0x7f1c08a60190>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Learning the model parameters\n",
    "# Fitting the model using Maximum Likelihood Estimator\n",
    "\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "mle = MaximumLikelihoodEstimator(model=model_struct, data=samples)\n",
    "\n",
    "# Estimating the CPD for a single node.\n",
    "print(mle.estimate_cpd(node=\"FIO2\"))\n",
    "print(mle.estimate_cpd(node=\"CVP\"))\n",
    "\n",
    "# Estimating CPDs for all the nodes in the model\n",
    "mle.get_parameters()[:10]  # Show just the first 10 CPDs in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying that the learned parameters are almost equal.\n",
    "np.allclose(\n",
    "    alarm_model.get_cpds(\"FIO2\").values, mle.estimate_cpd(\"FIO2\").values, atol=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "| FIO2(LOW)    | 0.0544554 |\n",
      "+--------------+-----------+\n",
      "| FIO2(NORMAL) | 0.945545  |\n",
      "+--------------+-----------+\n",
      "+-------------+-----+----------------------+\n",
      "| LVEDVOLUME  | ... | LVEDVOLUME(NORMAL)   |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(HIGH)   | ... | 0.011372648991615681 |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(LOW)    | ... | 0.04095853161114888  |\n",
      "+-------------+-----+----------------------+\n",
      "| CVP(NORMAL) | ... | 0.9476688193972355   |\n",
      "+-------------+-----+----------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(HYPOVOLEMIA:2) at 0x7f1c08a0e8d0>,\n",
       " <TabularCPD representing P(LVEDVOLUME:3 | HYPOVOLEMIA:2, LVFAILURE:2) at 0x7f1c08a77910>,\n",
       " <TabularCPD representing P(STROKEVOLUME:3 | HYPOVOLEMIA:2, LVFAILURE:2) at 0x7f1c08a81b90>,\n",
       " <TabularCPD representing P(CVP:3 | LVEDVOLUME:3) at 0x7f1c08a60b50>,\n",
       " <TabularCPD representing P(PCWP:3 | LVEDVOLUME:3) at 0x7f1c08a77fd0>,\n",
       " <TabularCPD representing P(LVFAILURE:2) at 0x7f1c08a7fd10>,\n",
       " <TabularCPD representing P(HISTORY:2 | LVFAILURE:2) at 0x7f1c08a7d510>,\n",
       " <TabularCPD representing P(CO:3 | HR:3, STROKEVOLUME:3) at 0x7f1c08a18e50>,\n",
       " <TabularCPD representing P(ERRLOWOUTPUT:2) at 0x7f1c08a7f1d0>,\n",
       " <TabularCPD representing P(HRBP:3 | ERRLOWOUTPUT:2, HR:3) at 0x7f1c08a778d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the using Bayesian Estimator\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "\n",
    "best = BayesianEstimator(model=model_struct, data=samples)\n",
    "\n",
    "print(best.estimate_cpd(node=\"FIO2\", prior_type=\"BDeu\", equivalent_sample_size=1000))\n",
    "# Uniform pseudo count for each state. Can also accept an array of the size of CPD.\n",
    "print(best.estimate_cpd(node=\"CVP\", prior_type=\"dirichlet\", pseudo_counts=100))\n",
    "\n",
    "# Learning CPDs for all the nodes in the model. For learning all parameters with BDeU prior, a dict of\n",
    "# pseudo_counts need to be provided\n",
    "best.get_parameters(prior_type=\"BDeu\", equivalent_sample_size=1000)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "| FIO2(LOW)    | 0.05 |\n",
      "+--------------+------+\n",
      "| FIO2(NORMAL) | 0.95 |\n",
      "+--------------+------+\n",
      "+--------------+-----------+\n",
      "| FIO2(LOW)    | 0.0544554 |\n",
      "+--------------+-----------+\n",
      "| FIO2(NORMAL) | 0.945545  |\n",
      "+--------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Shortcut for learning all the parameters and adding the CPDs to the model.\n",
    "\n",
    "model_struct = BayesianNetwork(ebunch=alarm_model.edges())\n",
    "model_struct.fit(data=samples, estimator=MaximumLikelihoodEstimator)\n",
    "print(model_struct.get_cpds(\"FIO2\"))\n",
    "\n",
    "model_struct = BayesianNetwork(ebunch=alarm_model.edges())\n",
    "model_struct.fit(\n",
    "    data=samples,\n",
    "    estimator=BayesianEstimator,\n",
    "    prior_type=\"BDeu\",\n",
    "    equivalent_sample_size=1000,\n",
    ")\n",
    "print(model_struct.get_cpds(\"FIO2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec627197fd3f43349d97277c282707d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pgmpy.estimators import ExpectationMaximization as EM\n",
    "\n",
    "# Define a model structure with latent variables\n",
    "model_latent = BayesianNetwork(\n",
    "    ebunch=alarm_model.edges(), latents=[\"HYPOVOLEMIA\", \"LVEDVOLUME\", \"STROKEVOLUME\"]\n",
    ")\n",
    "\n",
    "# Dataset for latent model which doesn't have values for the latent variables\n",
    "samples_latent = samples.drop(model_latent.latents, axis=1)\n",
    "\n",
    "model_latent.fit(samples_latent, estimator=EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference in Discrete Bayesian Network\n",
    "\n",
    "In this notebook, we show a simple example for doing Exact inference in Bayesian Networks using pgmpy. We will be using the Asia network (http://www.bnlearn.com/bnrepository/#asia) for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc78146fa7884bbc9d43cc1bc64e4b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asia</th>\n",
       "      <th>tub</th>\n",
       "      <th>smoke</th>\n",
       "      <th>lung</th>\n",
       "      <th>bronc</th>\n",
       "      <th>either</th>\n",
       "      <th>xray</th>\n",
       "      <th>dysp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asia tub smoke lung bronc either xray dysp\n",
       "0   no  no    no   no    no     no   no   no\n",
       "1   no  no    no   no    no     no   no   no\n",
       "2   no  no    no   no    no     no   no   no\n",
       "3   no  no   yes   no    no     no   no   no\n",
       "4   no  no   yes   no    no     no   no   no"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the asia model from the bnlearn repository\n",
    "\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "asia_model = get_example_model(\"asia\")\n",
    "samples = BayesianModelSampling(asia_model).forward_sample(size=int(1e5))\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:  ['asia', 'tub', 'smoke', 'lung', 'bronc', 'either', 'xray', 'dysp']\n",
      "Edges:  [('asia', 'tub'), ('tub', 'either'), ('smoke', 'lung'), ('smoke', 'bronc'), ('lung', 'either'), ('bronc', 'dysp'), ('either', 'xray'), ('either', 'dysp')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(asia:2) at 0x7f1c09e07810>,\n",
       " <TabularCPD representing P(bronc:2 | smoke:2) at 0x7f1c09dfee50>,\n",
       " <TabularCPD representing P(dysp:2 | bronc:2, either:2) at 0x7f1c09dfe8d0>,\n",
       " <TabularCPD representing P(either:2 | lung:2, tub:2) at 0x7f1c09dfea90>,\n",
       " <TabularCPD representing P(lung:2 | smoke:2) at 0x7f1c09dfe650>,\n",
       " <TabularCPD representing P(smoke:2) at 0x7f1c09dfe210>,\n",
       " <TabularCPD representing P(tub:2 | asia:2) at 0x7f1c09dfe890>,\n",
       " <TabularCPD representing P(xray:2 | either:2) at 0x7f1c09d91cd0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nodes: \", asia_model.nodes())\n",
    "print(\"Edges: \", asia_model.edges())\n",
    "asia_model.get_cpds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the inference class\n",
    "\n",
    "Currently, pgmpy support two algorithms for inference: 1. Variable Elimination(ë³€ìˆ˜ ì¶•ì†Œ) and, 2. Belief Propagation(ì‹ ë¢° ì „íŒŒ). Both of these are exact inferece algorithms. The following example uses VariableElimination but BeliefPropagation has an identifcal API, so all the methods show below would also work for BeliefPropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the VariableElimination class\n",
    "\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "asia_infer = VariableElimination(asia_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Doing Inference using hard evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cf3e96de3c47b5986be20a6c9a0771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6547402920644cc9f05da06b0ce24a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "| bronc      |   phi(bronc) |\n",
      "+============+==============+\n",
      "| bronc(yes) |       0.3000 |\n",
      "+------------+--------------+\n",
      "| bronc(no)  |       0.7000 |\n",
      "+------------+--------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3a43530bad48209e60c9a2bc0666d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54112c658784d278bffaa9cdb998c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------------------+\n",
      "| bronc      | asia      |   phi(bronc,asia) |\n",
      "+============+===========+===================+\n",
      "| bronc(yes) | asia(yes) |            0.0060 |\n",
      "+------------+-----------+-------------------+\n",
      "| bronc(yes) | asia(no)  |            0.5940 |\n",
      "+------------+-----------+-------------------+\n",
      "| bronc(no)  | asia(yes) |            0.0040 |\n",
      "+------------+-----------+-------------------+\n",
      "| bronc(no)  | asia(no)  |            0.3960 |\n",
      "+------------+-----------+-------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a85cde628740c5a3f11ed90d884ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed18ad80c8f406fba81e1afc4f2b44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "| bronc      |   phi(bronc) |\n",
      "+============+==============+\n",
      "| bronc(yes) |       0.3000 |\n",
      "+------------+--------------+\n",
      "| bronc(no)  |       0.7000 |\n",
      "+------------+--------------+\n",
      "+-----------+-------------+\n",
      "| asia      |   phi(asia) |\n",
      "+===========+=============+\n",
      "| asia(yes) |      0.0100 |\n",
      "+-----------+-------------+\n",
      "| asia(no)  |      0.9900 |\n",
      "+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Computing the probability of bronc given smoke=no.\n",
    "q = asia_infer.query(variables=[\"bronc\"], evidence={\"smoke\": \"no\"})\n",
    "print(q)\n",
    "\n",
    "# Computing the joint probability of bronc and asia given smoke=yes\n",
    "q = asia_infer.query(variables=[\"bronc\", \"asia\"], evidence={\"smoke\": \"yes\"})\n",
    "print(q)\n",
    "\n",
    "# Computing the probabilities (not joint) of bronc and asia given smoke=no\n",
    "q = asia_infer.query(variables=[\"bronc\", \"asia\"], evidence={\"smoke\": \"no\"}, joint=False)\n",
    "for factor in q.values():\n",
    "    print(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dc3ed30d154716a2c316a43f4c74ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a0a0d97e344bda8cd41e1afa2b78fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bronc': 'no'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e401022e31f4083bbc876cb5ac4b819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4182c027deea4cd688106024ec10e08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bronc': 'yes', 'asia': 'no'}\n"
     ]
    }
   ],
   "source": [
    "# Computing the MAP of bronc given smoke=no.\n",
    "q = asia_infer.map_query(variables=[\"bronc\"], evidence={\"smoke\": \"no\"})\n",
    "print(q)\n",
    "\n",
    "# Computing the MAP of bronc and asia given smoke=yes\n",
    "q = asia_infer.map_query(variables=[\"bronc\", \"asia\"], evidence={\"smoke\": \"yes\"})\n",
    "print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ml_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7d9e5ad94e942f3362bfd1753da69b8338b1ca6cb731c0ecc0630d1f97e9201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
